{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4ec769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas numpy emoji langdetect transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f0f894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HRMic\\OneDrive - ADvTECH Ltd\\Documents\\VS code\\Python_VS\\TWITTER\\Research\\gpuEnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import csv\n",
    "import os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import urllib.request\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7852556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Left</td>\n",
       "      <td>@ USER Fuck Joe Biden fuck Ukraine fuck the De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right</td>\n",
       "      <td>Fly them back to their home country just like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Right</td>\n",
       "      <td>Wow ! I ca n't believe the @ USER . They 're s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right</td>\n",
       "      <td>@ USER @ USER @ USER The election be rig again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Right</td>\n",
       "      <td>@ USER @ USER @ USER @ USER @ USER Why be acto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0   Left  @ USER Fuck Joe Biden fuck Ukraine fuck the De...\n",
       "1  Right  Fly them back to their home country just like ...\n",
       "2  Right  Wow ! I ca n't believe the @ USER . They 're s...\n",
       "3  Right  @ USER @ USER @ USER The election be rig again...\n",
       "4  Right  @ USER @ USER @ USER @ USER @ USER Why be acto..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2024_Classified_Balanced.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926804b",
   "metadata": {},
   "source": [
    "## **Roberta Sentiment MODEL**\n",
    "https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a815a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HRMic\\OneDrive - ADvTECH Ltd\\Documents\\VS code\\Python_VS\\TWITTER\\Research\\gpuEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HRMic\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['negative', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, use_safetensors=True).to('cuda')\n",
    "\n",
    "# load label mapping\n",
    "mapping_link = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode(\"utf-8\").split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter=\"\\t\")\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "print(\"Labels:\", labels)\n",
    "# (Barbieri et al., 2020; cardiffnlp, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd96516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text (username and link replacement)\n",
    "# to follow consistency with the model's training data\n",
    "def preprocess(text): # (Barbieri et al., 2020; cardiffnlp, 2020)\n",
    "    new_text = []\n",
    "    for t in str(text).lower().split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc0c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get sentiment\n",
    "def getSentiment(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "        scores = output.logits[0].detach().cpu().numpy()\n",
    "        scores = softmax(scores)\n",
    "    pred_id = np.argmax(scores)\n",
    "    # return label and scores\n",
    "    return labels[pred_id], scores\n",
    "# (Barbieri et al., 2020; cardiffnlp, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "621b56fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Left</td>\n",
       "      <td>@ USER Fuck Joe Biden fuck Ukraine fuck the De...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.92917615, 0.06484142, 0.0059823976]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right</td>\n",
       "      <td>Fly them back to their home country just like ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.5898782, 0.3819204, 0.028201416]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Right</td>\n",
       "      <td>Wow ! I ca n't believe the @ USER . They 're s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.9500361, 0.044342536, 0.005621288]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right</td>\n",
       "      <td>@ USER @ USER @ USER The election be rig again...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.888374, 0.10098925, 0.010636724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Right</td>\n",
       "      <td>@ USER @ USER @ USER @ USER @ USER Why be acto...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.70596755, 0.28732908, 0.0067033595]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet sentiment_label  \\\n",
       "0   Left  @ USER Fuck Joe Biden fuck Ukraine fuck the De...        negative   \n",
       "1  Right  Fly them back to their home country just like ...        negative   \n",
       "2  Right  Wow ! I ca n't believe the @ USER . They 're s...        negative   \n",
       "3  Right  @ USER @ USER @ USER The election be rig again...        negative   \n",
       "4  Right  @ USER @ USER @ USER @ USER @ USER Why be acto...        negative   \n",
       "\n",
       "                          sentiment_probs  \n",
       "0  [0.92917615, 0.06484142, 0.0059823976]  \n",
       "1     [0.5898782, 0.3819204, 0.028201416]  \n",
       "2   [0.9500361, 0.044342536, 0.005621288]  \n",
       "3     [0.888374, 0.10098925, 0.010636724]  \n",
       "4  [0.70596755, 0.28732908, 0.0067033595]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the function to the DataFrame\n",
    "sentOutput = df[\"tweet\"].apply(getSentiment)\n",
    "# split tuple results into separate columns\n",
    "df[\"sentiment_label\"] = sentOutput.apply(lambda x: x[0])\n",
    "df[\"sentiment_probs\"] = sentOutput.apply(lambda x: x[1])\n",
    "df.head()\n",
    "# (Barbieri et al., 2020; cardiffnlp, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbace111",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['negative', 'neutral', 'positive']\n",
    "sentiment_counts = df.groupby(['label', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "# convert counts to proportions for each political leaning\n",
    "sentiment_avg = sentiment_counts.div(sentiment_counts.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "df.to_csv(\"2024_sentiment_robertaBase.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9644e0a",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7382cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Sentiment Distribution by Political Leaning:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment_label</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Left</th>\n",
       "      <td>0.484969</td>\n",
       "      <td>0.348419</td>\n",
       "      <td>0.166613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Right</th>\n",
       "      <td>0.548921</td>\n",
       "      <td>0.370285</td>\n",
       "      <td>0.080793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment_label  negative   neutral  positive\n",
       "label                                        \n",
       "Left             0.484969  0.348419  0.166613\n",
       "Right            0.548921  0.370285  0.080793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average sentiment probabilities by political leaning\n",
    "print(\"\\nAverage Sentiment Distribution by Political Leaning:\\n\")\n",
    "sentiment_avg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
