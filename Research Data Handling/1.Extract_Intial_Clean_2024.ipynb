{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa49605",
   "metadata": {},
   "source": [
    "### **Install and Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e28aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.2.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
      "Downloading pyahocorasick-2.2.0-cp313-cp313-win_amd64.whl (35 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy emoji langdetect contractions beautifulsoup4 pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup # BeautifulSoup for parsing HTML and XML documents (Richardson, 2025)\n",
    "import re # Regular expression library for text processing\n",
    "import emoji\n",
    "import textwrap # textwrap library for formatting text\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "# NLP processing libraries # (NLTK Project, 2024)\n",
    "# Natural Language Toolkit (NLTK) is a suite of libraries and programs for\n",
    "# statistical natural language processing (NLP) \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions \n",
    "from langdetect import detect, detect_langs, DetectorFactory\n",
    "from collections import Counter\n",
    "from emoji import EMOJI_DATA\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a6121f",
   "metadata": {},
   "source": [
    "### **Read from CSV file: 2024**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def2b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show full column content\n",
    "pd.set_option(\"display.max_colwidth\", None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fcbf4",
   "metadata": {},
   "source": [
    "#### **Data Clean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87581447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@iFightForKids What if it was actually biden biting the secret service agents and they just blamed the dogs instead?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   text\n",
       "0  @iFightForKids What if it was actually biden biting the secret service agents and they just blamed the dogs instead?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"output/2024_LD_1.csv\")\n",
    "df = pd.read_csv(\"Raw Data/2024_Sample_Complete.csv\")\n",
    "# df = pd.read_csv(\"output/2024_Sample_Complete_2.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17370eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename cloumn text to tweet \n",
    "df = df.rename(columns={'text': 'tweet'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614df666",
   "metadata": {},
   "source": [
    "### **Duplicates, Null and Length Handling**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee2ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate tweet rows: 291477\n",
      "Number of rows after removing duplicates: 581780\n"
     ]
    }
   ],
   "source": [
    "duplicates= df[df.duplicated(subset=['tweet'], keep=False)]\n",
    "print(\"Number of duplicate tweet rows:\", len(duplicates))\n",
    "df = df.drop_duplicates(subset=['tweet'], keep='first').reset_index(drop=True)\n",
    "print(\"Number of rows after removing duplicates:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c378dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581780 entries, 0 to 581779\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   tweet   581780 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# # for 2024: minimize to 4000 rows \n",
    "# df = df.iloc[:6000]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a2771",
   "metadata": {},
   "source": [
    "**Handle Null Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165cd054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of null values in DataFrame:\n",
      "Number of rows after removing null tweet rows: 581780\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of null values in DataFrame:\")\n",
    "# pandas isnull() method to check for null values in the DataFrame\n",
    "# The null values will help to identify any missing data that may need to be addressed before analysis and machine learning tasks\n",
    "df.isnull().sum()\n",
    "df = df.dropna(subset=['tweet']).reset_index(drop=True)\n",
    "print(\"Number of rows after removing null tweet rows:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d113a2",
   "metadata": {},
   "source": [
    "**Handle Text Lenghth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84439beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 shortest tweets:\n",
      "üíØ\n",
      "--------------------------------------------------\n",
      "Q\n",
      "--------------------------------------------------\n",
      "üòÆ\n",
      "--------------------------------------------------\n",
      "ü§Æ\n",
      "--------------------------------------------------\n",
      "üíô\n",
      "--------------------------------------------------\n",
      "Shape of the DataFrame after dropping short tweets: (573089, 1)\n"
     ]
    }
   ],
   "source": [
    "# remove tweets with less than 2 words to ensure meaningful analysis\n",
    "# Initialize text_list from the 'tweet' column in the DataFrame\n",
    "text_list = df['tweet'].tolist() \n",
    "text_list = sorted(text_list, key=lambda x: len(str(x)))\n",
    "\n",
    "# Display top 5 shortest tweets\n",
    "print(\"Top 5 shortest tweets:\")\n",
    "for tweet in text_list[:5]:\n",
    "    wrap_text = textwrap.fill(str(tweet), width=80)\n",
    "    print(wrap_text)\n",
    "    print(\"-\" * 50)\n",
    "# drop tweets with with just two words from dataframe\n",
    "df = df[df['tweet'].str.split().str.len() > 2]\n",
    "# Display the shape of the DataFrame after dropping short tweets\n",
    "print(\"Shape of the DataFrame after dropping short tweets:\", df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d7938",
   "metadata": {},
   "source": [
    "## **Normilazation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8cb761",
   "metadata": {},
   "source": [
    "**Normalize whitespace (\\n ‚Üí space)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d313611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']= df['tweet'].str.replace(r'\\s+', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81edbffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@iFightForKids What if it was actually biden biting the secret service agents and they just blamed the dogs instead?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Kamala Harris' America. Where Islamic Terrorists are allowed to cross the border, buy guns, them murder innocent people while shouting \"allahu akbar\". #KamalaDumpsterFire #Kamala Surge #DemocratsHateAmerica #VoteTrumpToSaveAmerica #DeportThemAll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Penelopesire1 @kylenabecker I was just talking to my wife about that, when Kamala Harris said she wouldn‚Äôt change anything in the past 3 1/2 years versus Trump telling all about the mistakes made his 1st term and won‚Äôt make them again, that‚Äôs apparent, thank God üôè</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BarackObama @vicblends I would take Donald Trump‚Äòs family values and the way he governs over Kamala any day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFL legend gives angry response to claims he endorsed Kamala Harrisüëèüëè https://t.co/0BFG0FnRtV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                       tweet\n",
       "0                                                                                                                                                       @iFightForKids What if it was actually biden biting the secret service agents and they just blamed the dogs instead?\n",
       "1           Welcome to Kamala Harris' America. Where Islamic Terrorists are allowed to cross the border, buy guns, them murder innocent people while shouting \"allahu akbar\". #KamalaDumpsterFire #Kamala Surge #DemocratsHateAmerica #VoteTrumpToSaveAmerica #DeportThemAll\n",
       "2  @Penelopesire1 @kylenabecker I was just talking to my wife about that, when Kamala Harris said she wouldn‚Äôt change anything in the past 3 1/2 years versus Trump telling all about the mistakes made his 1st term and won‚Äôt make them again, that‚Äôs apparent, thank God üôè\n",
       "3                                                                                                                                                              @BarackObama @vicblends I would take Donald Trump‚Äòs family values and the way he governs over Kamala any day.\n",
       "4                                                                                                                                                                              NFL legend gives angry response to claims he endorsed Kamala Harrisüëèüëè https://t.co/0BFG0FnRtV"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de3036",
   "metadata": {},
   "source": [
    "**Ellipsis, comma and quotations**\n",
    "- (‚Ä¶, U+2026) into three dots (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b01be3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeText(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Normalize ellipsis (‚Ä¶) to \"...\"\n",
    "    text = text.replace(\"‚Ä¶\", \"...\")\n",
    "    \n",
    "    # Normalize curly quotes to straight quotes\n",
    "    text = text.replace(\"‚Äú\", '\"').replace(\"‚Äù\", '\"')\n",
    "    text = text.replace(\"‚Äò\", \"'\").replace(\"‚Äô\", \"'\")\n",
    "    \n",
    "    # Normalize en-dash and em-dash to plain dash\n",
    "    text = text.replace(\"‚Äì\", \"-\").replace(\"‚Äî\", \"-\")\n",
    "    \n",
    "    # Collapse multiple dots into three max (avoid \"......\")\n",
    "    text = re.sub(r\"\\.{3,}\", \"...\", text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "829328a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']= df['tweet'].apply(normalizeText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e86493",
   "metadata": {},
   "source": [
    "**Handle Non-English Tweets**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38cba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DetectorFactory.seed = 0  # deterministic results\n",
    "\n",
    "# # Regex patterns\n",
    "# urlPattern = re.compile(r'https?://\\S+')\n",
    "# mentionPattern = re.compile(r'@\\w+')\n",
    "\n",
    "# # Remove URLs, mentions, and emojis to evaluate language\n",
    "# def removeNoise(text: str):    \n",
    "#     t = urlPattern.sub(' ', str(text))\n",
    "#     t = mentionPattern.sub(' ', t)\n",
    "\n",
    "#     # Count hashtags but keep them in the text\n",
    "#     numHash = t.count('#')\n",
    "\n",
    "#     # Remove emojis only\n",
    "#     cleanTweet = ''.join(ch if ch not in EMOJI_DATA else ' ' for ch in t)\n",
    "\n",
    "#     return cleanTweet.strip(), numHash\n",
    "\n",
    "# # Remove text that only contains hashtags or is not in English\n",
    "# def removeLanguage(df, col=\"text\", verbose=True):\n",
    "#     detected = []\n",
    "#     numRemoved = []\n",
    "#      # check each row\n",
    "#     def validate(row_text):\n",
    "#         text, numHash = removeNoise(row_text)\n",
    "#         words = text.split()\n",
    "\n",
    "#         # Filter hashtag-only tweets (>=3 hashtags but very few words)\n",
    "#         if numHash >= 3 and len(words) < 4:\n",
    "#             if verbose:\n",
    "#                 print(f\"Where Just Hashtag Tweets: {row_text}\")\n",
    "#             detected.append(\"hashtag_only\")\n",
    "#             numRemoved.append(row_text)\n",
    "#             return False\n",
    "\n",
    "#         try:\n",
    "#             langs = detect_langs(text or \"a\")\n",
    "#             best = langs[0]\n",
    "#             lang, prob = best.lang, best.prob\n",
    "#         except Exception:\n",
    "#             lang, prob = \"error\", 0.0\n",
    "\n",
    "#         detected.append(lang)\n",
    "\n",
    "#         if lang == \"en\" and prob >= 0.55:\n",
    "#             return True\n",
    "#         else:\n",
    "#             if verbose:\n",
    "#                 print(f\"Where Non-English Tweets({lang} {prob:.2f}): {row_text}\")\n",
    "#             numRemoved.append(row_text)\n",
    "#             return False\n",
    "\n",
    "#     mask = df[col].apply(validate)\n",
    "#     filtered = df[mask].copy()\n",
    "\n",
    "#     if verbose:\n",
    "#         print(\"\\n Summary of Language Found:\")\n",
    "#         for k, v in Counter(detected).most_common():\n",
    "#             print(f\"{k}: {v}\")\n",
    "#         print(f\"\\nRemaining rows: {len(filtered)} / {len(df)}\")\n",
    "\n",
    "#     return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749f6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectorFactory.seed = 0  # keep deterministic results\n",
    "\n",
    "urlPattern = re.compile(r'https?://\\S+')\n",
    "mentionPattern = re.compile(r'@\\w+')\n",
    "\n",
    "def pre_clean(series: pd.Series):\n",
    "    cleaned = series.astype(str)\n",
    "    cleaned = cleaned.str.replace(urlPattern, ' ', regex=True)\n",
    "    cleaned = cleaned.str.replace(mentionPattern, ' ', regex=True)\n",
    "    num_hash = cleaned.str.count('#')\n",
    "    cleaned = cleaned.apply(lambda s: ''.join(' ' if ch in EMOJI_DATA else ch for ch in s).strip())\n",
    "    return cleaned, num_hash\n",
    "\n",
    "def detect_lang_safe(text):\n",
    "    try:\n",
    "        return detect_langs(text or \"a\")[0]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def removeLanguage(df, col=\"text\", verbose=True, min_prob=0.55, workers=None):\n",
    "    cleaned, num_hash = pre_clean(df[col])\n",
    "\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    mask &= ~((num_hash >= 3) & (cleaned.str.split().str.len() < 4))\n",
    "\n",
    "    subset = cleaned[mask]\n",
    "\n",
    "    cache = {}\n",
    "    def detect_with_cache(text):\n",
    "        if text in cache:\n",
    "            return cache[text]\n",
    "        best = detect_lang_safe(text)\n",
    "        cache[text] = best\n",
    "        return best\n",
    "\n",
    "    if workers and len(subset) > 0:\n",
    "        def detect_batch(chunk):\n",
    "            DetectorFactory.seed = 0\n",
    "            return [detect_with_cache(text) for text in chunk]\n",
    "        with ProcessPoolExecutor(max_workers=workers) as pool:\n",
    "            results = sum(pool.map(detect_batch, np.array_split(subset.values, workers)), [])\n",
    "    else:\n",
    "        results = [detect_with_cache(text) for text in subset.values]\n",
    "\n",
    "    detected = []\n",
    "    keep = pd.Series(False, index=subset.index)\n",
    "    for idx, best in zip(subset.index, results):\n",
    "        if best is None:\n",
    "            detected.append((\"error\", 0.0))\n",
    "            continue\n",
    "        lang, prob = best.lang, best.prob\n",
    "        detected.append((lang, prob))\n",
    "        if lang == \"en\" and prob >= min_prob:\n",
    "            keep.at[idx] = True\n",
    "\n",
    "    filtered = df.loc[keep.reindex(df.index, fill_value=False)].copy()\n",
    "\n",
    "    if verbose:\n",
    "        tallies = Counter(lang for lang, _ in detected)\n",
    "        print(\"\\nSummary of Language Found:\")\n",
    "        for lang, count in tallies.most_common():\n",
    "            print(f\"{lang}: {count}\")\n",
    "        print(f\"\\nRemaining rows: {len(filtered)} / {len(df)}\")\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a98247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove if not english and not hashtag only\n",
    "df = removeLanguage(df, col=\"tweet\", verbose=False)\n",
    "# remove from df \"tweet\" column so that index that are english and not hashtag only are kept\n",
    "df = df[df['tweet'].notna()].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cec98733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 481427 entries, 0 to 481426\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   tweet   481427 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeeb336c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@iFightForKids What if it was actually biden biting the secret service agents and they just blamed the dogs instead?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Kamala Harris' America. Where Islamic Terrorists are allowed to cross the border, buy guns, them murder innocent people while shouting \"allahu akbar\". #KamalaDumpsterFire #Kamala Surge #DemocratsHateAmerica #VoteTrumpToSaveAmerica #DeportThemAll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Penelopesire1 @kylenabecker I was just talking to my wife about that, when Kamala Harris said she wouldn't change anything in the past 3 1/2 years versus Trump telling all about the mistakes made his 1st term and won't make them again, that's apparent, thank God üôè</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BarackObama @vicblends I would take Donald Trump's family values and the way he governs over Kamala any day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFL legend gives angry response to claims he endorsed Kamala Harrisüëèüëè https://t.co/0BFG0FnRtV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                       tweet\n",
       "0                                                                                                                                                       @iFightForKids What if it was actually biden biting the secret service agents and they just blamed the dogs instead?\n",
       "1           Welcome to Kamala Harris' America. Where Islamic Terrorists are allowed to cross the border, buy guns, them murder innocent people while shouting \"allahu akbar\". #KamalaDumpsterFire #Kamala Surge #DemocratsHateAmerica #VoteTrumpToSaveAmerica #DeportThemAll\n",
       "2  @Penelopesire1 @kylenabecker I was just talking to my wife about that, when Kamala Harris said she wouldn't change anything in the past 3 1/2 years versus Trump telling all about the mistakes made his 1st term and won't make them again, that's apparent, thank God üôè\n",
       "3                                                                                                                                                              @BarackObama @vicblends I would take Donald Trump's family values and the way he governs over Kamala any day.\n",
       "4                                                                                                                                                                              NFL legend gives angry response to claims he endorsed Kamala Harrisüëèüëè https://t.co/0BFG0FnRtV"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106c6ca",
   "metadata": {},
   "source": [
    "### **Save to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9b4ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('2024_Sample_Complete_Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f872ff0",
   "metadata": {},
   "source": [
    "Deepak, 2017. nltk - wordnet lemmatization and pos tagging in python - Stack Overflow. [online] \n",
    "Available at: <https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python> [Accessed 26 June 2025].\n",
    "Dutta, T., 2024. Sentiment Analysis of Customer Reviews: A Guide for Beginners | by Tanushree Dutta | Medium. [online] \n",
    "Available at: <https://medium.com/@14duttatanushreeya/sentiment-analysis-of-customer-reviews-a-guide-for-beginners-4a5f2194a121> \n",
    "GeeksforGeeks, 2024a. How to Remove HTML Tags from String in Python - GeeksforGeeks. [online] Available at: <https://www.geeksforgeeks.org/python/how-to-remove-html-tags-from-string-in-python/> [Accessed 25 June 2025].\n",
    "GeeksforGeeks, 2024b. Python | Lemmatization with NLTK - GeeksforGeeks. [online] Available at: <https://www.geeksforgeeks.org/python-lemmatization-with-nltk/> [Accessed 26 June 2025].\n",
    "Lane, K., 2021. Tokenization with NLTK. When it comes to NLP, tokenization is a‚Ä¶ | by Kelsey Lane | Medium. [online] Available at: <https://medium.com/%40kelsklane/tokenization-with-nltk-52cd7b88c7d> [Accessed 26 June 2025].\n",
    "NLTK Project, 2024. NLTK‚ÄØ:: Natural Language Toolkit. [online] \n",
    "Available at: <https://www.nltk.org/> [Accessed 27 June 2025].\n",
    "Richardson, L., 2025. Beautiful Soup Documentation ‚Äî Beautiful Soup 4.13.0 documentation. [online] \n",
    "Available at: <https://www.crummy.com/software/BeautifulSoup/bs4/doc/> [Accessed 27 June 2025]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
